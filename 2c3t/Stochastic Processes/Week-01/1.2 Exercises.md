Exercises

(a) Three dice are rolled. Define the events
A â‰¡ The first and second show the same.
B â‰¡ The second and third show the same.
C â‰¡ The first and third show the same.

Show that the events A, B, and C are pairwise independent but not independent.

(b) A total of n coins are flipped, of which exactly one is biased, and the rest are fair. Let A be the event that the n coins together show exactly one head or exactly one tail; let B be the event that the biased coin shows a head. Prove that A and B are independent. Now let C be the event that one of the fair coins shows a head. Is A independent of C? Is A independent of B âˆ© C?

(c) Testing. A test for a disease gives a positive result with probability 99/100 when given to an ill person, and with probability 1/100 when given to a well person. What is the probability that you have the disease if the test shows positive and
(i) the disease affects one person in 100?
(ii) the disease affects one person in 10^5?

Discuss the implications of your results.

## Proofs

__1.2.1) Conditional probability__, ð‘ƒ(ð´|ðµ), means you are looking for the probability of a certain event (ð´), given a certain amount of information (ðµ).

Any time you are looking for the probability of just event ð´

you are assuming an underlying probability space Î©. Therefore, ð‘ƒ(ð´) can also be viewed as the ð‘ƒ(ð´|Î©)=ð‘ƒ(ð´âˆ©Î©)/ð‘ƒ(Î©) where ð‘ƒ(Î©)=1 and ð‘ƒ(ð´âˆ©Î©)=ð‘ƒ(ð´).

Moreover, ð‘ƒ(ð´|ðµ) assumes that you are still interested in finding ð‘ƒ(ð´); however, your sample space Î© is now being restricted only to the event ðµ.

With this is mind, the probability of interest becomes ð‘ƒ(ð´âˆ©ðµ); that is the probability of both A and B occurring. However, you still have to divide by ð‘ƒ(ðµ) because the underlying probability space no longer has probability 1.

1.2.4)  $\mathrm P(A^c\mid B)=1-\mathrm P(A\mid B)$

1. Express $A^{c} \cap B$ in terms of A âˆ© B:

The events $A \cap B$ and $A^{c} \cap B$ are mutually exclusive (they cannot happen at the same time), and their union is B:
$$(A \cap B) \cup (A^{c} \cap B) = B$$

Therefore, by the probability of the union of mutually exclusive events:
$$P(A \cap B) + P(A^{c} \cap B) = P(B)$$

2. Solve for $P(A^c âˆ© B)$:

$$P(A^{c} \cap B) = P(B) - P(A \cap B)$$

3. Divide both sides by P(B) (assuming P(B) > 0):
$$\frac{P(A^{c} \cap B)}{P(B)} = \frac{P(B) - P(A \cap B)}{P(B)}$$
$$\frac{P(A^{c} \cap B)}{P(B)} = 1 - \frac{P(A \cap B)}{P(B)}$$

4. Recognize the definitions of conditional probabilities:
$$P(A^c|B) = 1 - P(A|B)$$

1.2.5) __Partition Rule__

$$
\mathrm P(A)=\mathrm P(A\mid B)\mathrm P(B)+\mathrm P(A\mid B^c)\mathrm P(B^c)
$$
$$
\mathrm P(A)= (A \cap B) \cup (A \cap B^{c}) 
$$
Now, recall the definition of conditional probability:

$P(A|B) = \frac{P(A\cap B)}{P(B)}$

=> $P(A \cap B) = P(A|B)P(B)$

Similarly,

$P(A \cap B^{c}) = P(A|B^{c})P(B^{c})$

Substituting these back into the equation for $P(A)$;

$P(A) = P(A|B)P(B) + P(A|B^c)P(B^c)$

__1.2.6) Multiplication Rule__
$$
P\left(\bigcap_{r=1}^{n+1} A_r\right) = P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)\cdots P\left(A_{n+1}\left|\bigcap_{r=1}^n A_r\right.\right).
$$

You know that the definition of conditional probability is
$$P(B|A) = \frac{P(A âˆ© B)}{P(A)},$$
so just apply the definition to every term in the right hand side of your equation. Starting with

$$P(A_1) P(A_2|A_1) P(A_3|A_1 âˆ© A_2)...P(A_n|A_1 âˆ© A_2 âˆ© ... âˆ© A_{n-1})$$

and applying the definition of conditional probability to each term we get

$$P(A_1) \frac{P(A_1 âˆ© A_2)}{P(A_1)} \frac{P(A_1 âˆ© A_2 âˆ© A_3)}{P(A_1 âˆ© A_2)}...\frac{P(A_1 âˆ© A_2 âˆ© ... âˆ© A_n)}{P(A_1 âˆ© A_2 âˆ© ... âˆ© A_{n-1})}$$

And almost every term will cancel out, except $P(A_1 âˆ© A_2 âˆ© ... âˆ© A_n)$.
Hence
$$P(A_1 âˆ© A_2 âˆ© ... âˆ© A_n)=P(A_1) P(A_2|A_1) P(A_3|A_1 âˆ© A_2)...P(A_n|A_1 âˆ© A_2 âˆ© ... âˆ© A_{n-1}).$$

1.2.7) Beta
$$
P(A_r | B) = \frac{P(B | A_r)P(A_r)}{\sum_{r=1}^{n} P(B | A_r)P(A_r)}.
$$
$P(Aâˆ©B) = P(A)P(B|A)$ 
$P(Aâˆ©B) = P(B)P(A|B)$ 
$P(B)P(A|B) = P(A)P(B|A)$ 
and thus
$P(A|B) = \frac{P(A)P(B|A)}{P(B)}$ 

[link](https://www.youtube.com/watch?v=akClB1J6b28) to proof 

1.2.7) Independent events

If events independent $P(A|B)=P(A)$

$P(A|B) = \frac{P(A \cap B)}{P(B)}$ 
$P(A\cap B) = P(A)P(B)$
